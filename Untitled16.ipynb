{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1053438\n",
      "The Project Gutenberg EBook of Little Women, by Louisa May Alcott\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away\n"
     ]
    }
   ],
   "source": [
    "url = \"http://www.gutenberg.org/files/514/514.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Little',\n",
       " 'Women',\n",
       " ',',\n",
       " 'by',\n",
       " 'Louisa',\n",
       " 'May',\n",
       " 'Alcott',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " '.',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it',\n",
       " ',',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advhfTokens = nltk.word_tokenize(raw)\n",
    "advhfTokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'little',\n",
       " 'women',\n",
       " ',',\n",
       " 'by',\n",
       " 'louisa',\n",
       " 'may',\n",
       " 'alcott',\n",
       " 'this',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " '.',\n",
       " 'you',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it',\n",
       " ',',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'license']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advhfwords = [w.lower() for w in advhfTokens]\n",
    "advhfwords[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'little',\n",
       " 'women',\n",
       " ',',\n",
       " 'by',\n",
       " 'louisa',\n",
       " 'may',\n",
       " 'alcott',\n",
       " 'this',\n",
       " 'is',\n",
       " 'for',\n",
       " 'use',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " '.',\n",
       " 'you',\n",
       " 'copy',\n",
       " 'it',\n",
       " 'give',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'under',\n",
       " 'terms',\n",
       " 'license',\n",
       " 'included',\n",
       " 'online',\n",
       " 'www.gutenberg.net',\n",
       " 'title',\n",
       " ':',\n",
       " 'author',\n",
       " 'posting',\n",
       " 'date',\n",
       " 'september',\n",
       " '13',\n",
       " '2008',\n",
       " '[',\n",
       " '#']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(advhfwords)\n",
    "fdistkeys = list(fdist.keys())\n",
    "fdistkeys[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(',', 19036)\n",
      "('and', 8110)\n",
      "('.', 7958)\n",
      "('the', 7670)\n",
      "('to', 5144)\n",
      "('a', 4494)\n",
      "('i', 3946)\n",
      "('of', 3518)\n",
      "(\"''\", 3344)\n",
      "('her', 3240)\n",
      "('``', 3008)\n",
      "('it', 2759)\n",
      "('in', 2500)\n",
      "('you', 2435)\n",
      "('she', 2343)\n",
      "('for', 2228)\n",
      "('was', 2071)\n",
      "('as', 1977)\n",
      "('that', 1929)\n",
      "('with', 1853)\n",
      "(\"n't\", 1592)\n",
      "('he', 1592)\n",
      "('but', 1469)\n",
      "(\"'s\", 1407)\n",
      "('jo', 1359)\n",
      "('do', 1224)\n",
      "('so', 1130)\n",
      "('his', 1117)\n",
      "('had', 1093)\n",
      "('at', 1066)\n",
      "('be', 1014)\n",
      "('on', 974)\n",
      "('not', 964)\n",
      "('is', 918)\n",
      "('if', 913)\n",
      "('all', 875)\n",
      "('?', 865)\n",
      "('my', 835)\n",
      "('said', 827)\n",
      "('him', 782)\n",
      "('have', 765)\n",
      "('me', 753)\n",
      "('!', 747)\n",
      "('little', 725)\n",
      "('one', 718)\n",
      "('they', 718)\n",
      "('when', 708)\n",
      "('meg', 683)\n",
      "('amy', 647)\n",
      "('up', 638)\n"
     ]
    }
   ],
   "source": [
    "topkeys = fdist.most_common(50)\n",
    "for pair in topkeys:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regular Expression to match non-alphabetic characters\n",
    "import re\n",
    "# this regular expression pattern matches any word that contains all non-alphabetical\n",
    "#   lower-case characters [^a-z]+\n",
    "# the beginning ^ and ending $ require the match to begin and end on a word boundary \n",
    "pattern = re.compile('^[^a-z]+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193296\n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'little', 'women', 'by', 'louisa', 'may', 'alcott', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www.gutenberg.net', 'title', 'little', 'women', 'author', 'louisa', 'may', 'alcott', 'posting', 'date', 'september', 'ebook', 'release', 'date', 'may', 'this', 'file', 'last', 'updated', 'on', 'august', 'language', 'english', 'character', 'set', 'encoding', 'ascii', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'little', 'women', 'little', 'women', 'by', 'louisa', 'may', 'alcott', 'contents', 'part', 'one', 'playing', 'pilgrims']\n"
     ]
    }
   ],
   "source": [
    "# apply the function to remove non-alphabetical words in emmawords\n",
    "fiwords = [w for w in advhfwords if not alpha_filter(w)]\n",
    "print(len(fiwords))\n",
    "print(fiwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193296\n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'little', 'women', 'by', 'louisa', 'may', 'alcott', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www.gutenberg.net', 'title', 'little', 'women', 'author', 'louisa', 'may', 'alcott', 'posting', 'date', 'september', 'ebook', 'release', 'date', 'may', 'this', 'file', 'last', 'updated', 'on', 'august', 'language', 'english', 'character', 'set', 'encoding', 'ascii', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'little', 'women', 'little', 'women', 'by', 'louisa', 'may', 'alcott', 'contents', 'part', 'one', 'playing', 'pilgrims']\n"
     ]
    }
   ],
   "source": [
    "# apply the function to remove non-alphabetical words in emmawords\n",
    "fiwords = [w for w in advhfwords if not alpha_filter(w)]\n",
    "print(len(fiwords))\n",
    "print(fiwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that takes a word and returns true if it consists only\n",
    "#   of non-alphabetic characters  (assumes import re)\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193296\n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'little', 'women', 'by', 'louisa', 'may', 'alcott', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www.gutenberg.net', 'title', 'little', 'women', 'author', 'louisa', 'may', 'alcott', 'posting', 'date', 'september', 'ebook', 'release', 'date', 'may', 'this', 'file', 'last', 'updated', 'on', 'august', 'language', 'english', 'character', 'set', 'encoding', 'ascii', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'little', 'women', 'little', 'women', 'by', 'louisa', 'may', 'alcott', 'contents', 'part', 'one', 'playing', 'pilgrims']\n"
     ]
    }
   ],
   "source": [
    "# apply the function to remove non-alphabetical words in emmawords\n",
    "fiwords = [w for w in advhfwords if not alpha_filter(w)]\n",
    "print(len(fiwords))\n",
    "print(fiwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number stopwords: 153\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print('number stopwords:', len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = ['mr.', 'mrs','nt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords1 = stopwords + nwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96997\n"
     ]
    }
   ],
   "source": [
    "stoppedfiwords = [w for w in fiwords if not w in stopwords1]\n",
    "print(len(stoppedfiwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"n't\", 1592)\n",
      "(\"'s\", 1407)\n",
      "('jo', 1359)\n",
      "('said', 827)\n",
      "('little', 725)\n",
      "('one', 718)\n",
      "('meg', 683)\n",
      "('amy', 647)\n",
      "('laurie', 596)\n",
      "('like', 581)\n",
      "('would', 536)\n",
      "('beth', 465)\n",
      "('could', 444)\n",
      "('good', 431)\n",
      "('go', 385)\n",
      "('never', 374)\n",
      "('mother', 371)\n",
      "('much', 371)\n",
      "(\"'m\", 371)\n",
      "('old', 365)\n",
      "('see', 360)\n",
      "(\"'ll\", 340)\n",
      "('well', 338)\n",
      "('away', 331)\n",
      "('time', 321)\n",
      "('know', 318)\n",
      "('march', 316)\n",
      "('made', 292)\n",
      "('think', 279)\n",
      "('young', 277)\n",
      "('say', 275)\n",
      "('come', 274)\n",
      "('home', 272)\n",
      "('came', 271)\n",
      "('went', 268)\n",
      "('girls', 267)\n",
      "('dear', 263)\n",
      "('make', 257)\n",
      "('got', 255)\n",
      "('face', 254)\n",
      "('asked', 252)\n",
      "('shall', 249)\n",
      "('day', 242)\n",
      "('looked', 240)\n",
      "('get', 239)\n",
      "('look', 238)\n",
      "('mrs.', 237)\n",
      "('tell', 217)\n",
      "('things', 214)\n",
      "('long', 214)\n"
     ]
    }
   ],
   "source": [
    "fidist = FreqDist(stoppedfiwords)\n",
    "fiitems = fidist.most_common(50)\n",
    "for item in fiitems:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'project'), ('project', 'gutenberg'), ('gutenberg', 'ebook'), ('ebook', 'of'), ('of', 'little'), ('little', 'women'), ('women', ','), (',', 'by'), ('by', 'louisa'), ('louisa', 'may'), ('may', 'alcott'), ('alcott', 'this'), ('this', 'ebook'), ('ebook', 'is'), ('is', 'for'), ('for', 'the'), ('the', 'use'), ('use', 'of'), ('of', 'anyone'), ('anyone', 'anywhere')]\n"
     ]
    }
   ],
   "source": [
    "# look at some bigrams using the nltk.bigrams function\n",
    "fibigrams = list(nltk.bigrams(advhfwords))\n",
    "print(fibigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'> ((',', 'and'), 0.019878349211886023)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(advhfwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "print(type(scored))\n",
    "first = scored[0]\n",
    "print(type(first), first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.019878349211886023)\n",
      "(('.', '``'), 0.006884824173188864)\n",
      "(('.', \"''\"), 0.004944515903987442)\n",
      "((',', 'but'), 0.004809348361638579)\n",
      "((\"''\", '``'), 0.0045128518171313955)\n",
      "((',', \"''\"), 0.004377684274782533)\n",
      "((',', 'for'), 0.0039198587281170285)\n",
      "(('.', 'i'), 0.0029954871481828686)\n",
      "(('?', \"''\"), 0.0027818352264056333)\n",
      "(('of', 'the'), 0.0027425930366914474)\n",
      "(('in', 'the'), 0.0027295123067867188)\n",
      "(('``', 'i'), 0.0025420218448189407)\n",
      "((',', 'as'), 0.002302208463232248)\n",
      "(('do', \"n't\"), 0.0022498855436133337)\n",
      "((',', 'i'), 0.002236804813708605)\n",
      "(('with', 'a'), 0.0019272275392966927)\n",
      "((\"''\", 'said'), 0.0019185070526935404)\n",
      "((',', 'with'), 0.0018836251062809306)\n",
      "(('it', ','), 0.0018531034031698968)\n",
      "(('jo', ','), 0.0018443829165667445)\n",
      "(('and', 'i'), 0.0017179358608210339)\n",
      "(('and', 'the'), 0.001683053914408424)\n",
      "(('i', \"'m\"), 0.0016002092916784756)\n",
      "(('to', 'the'), 0.0015217249122501035)\n",
      "(('to', 'be'), 0.0014955634524406462)\n",
      "((',', '``'), 0.0014127188297106978)\n",
      "((',', 'she'), 0.0014127188297106978)\n",
      "(('!', \"''\"), 0.0013996380998059692)\n",
      "((',', 'the'), 0.0013865573699012406)\n",
      "(('it', 'was'), 0.0013516754234886308)\n",
      "(('in', 'a'), 0.0013124332337744447)\n",
      "(('for', 'the'), 0.0013037127471712921)\n",
      "(('i', 'do'), 0.0012862717739649872)\n",
      "(('it', \"'s\"), 0.00126011031415553)\n",
      "((',', 'who'), 0.0012557500708539537)\n",
      "(('.', 'the'), 0.0012470295842508011)\n",
      "((',', 'so'), 0.00122522836774292)\n",
      "(('.', 'she'), 0.0012121476378381913)\n",
      "(('on', 'the'), 0.0011816259347271578)\n",
      "(('.', 'it'), 0.001164184961520853)\n",
      "(('at', 'the'), 0.0011598247182192766)\n",
      "(('as', 'if'), 0.0011380235017113955)\n",
      "(('it', '.'), 0.0010987813119972094)\n",
      "(('as', 'she'), 0.0010857005820924808)\n",
      "(('she', 'had'), 0.0010202969325688374)\n",
      "(('in', 'her'), 0.0009897752294578037)\n",
      "((',', 'jo'), 0.000937452309838889)\n",
      "(('her', ','), 0.0009330920665373128)\n",
      "(('she', 'was'), 0.0009243715799341604)\n",
      "((\"''\", 'and'), 0.0009200113366325841)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.019878349211886023)\n",
      "(('.', '``'), 0.006884824173188864)\n",
      "(('.', \"''\"), 0.004944515903987442)\n",
      "((',', 'but'), 0.004809348361638579)\n",
      "((\"''\", '``'), 0.0045128518171313955)\n",
      "((',', \"''\"), 0.004377684274782533)\n",
      "((',', 'for'), 0.0039198587281170285)\n",
      "(('.', 'i'), 0.0029954871481828686)\n",
      "(('?', \"''\"), 0.0027818352264056333)\n",
      "(('of', 'the'), 0.0027425930366914474)\n",
      "(('in', 'the'), 0.0027295123067867188)\n",
      "(('``', 'i'), 0.0025420218448189407)\n",
      "((',', 'as'), 0.002302208463232248)\n",
      "(('do', \"n't\"), 0.0022498855436133337)\n",
      "((',', 'i'), 0.002236804813708605)\n",
      "(('with', 'a'), 0.0019272275392966927)\n",
      "((\"''\", 'said'), 0.0019185070526935404)\n",
      "((',', 'with'), 0.0018836251062809306)\n",
      "(('it', ','), 0.0018531034031698968)\n",
      "(('jo', ','), 0.0018443829165667445)\n",
      "(('and', 'i'), 0.0017179358608210339)\n",
      "(('and', 'the'), 0.001683053914408424)\n",
      "(('i', \"'m\"), 0.0016002092916784756)\n",
      "(('to', 'the'), 0.0015217249122501035)\n",
      "(('to', 'be'), 0.0014955634524406462)\n",
      "((',', '``'), 0.0014127188297106978)\n",
      "((',', 'she'), 0.0014127188297106978)\n",
      "(('!', \"''\"), 0.0013996380998059692)\n",
      "((',', 'the'), 0.0013865573699012406)\n",
      "(('it', 'was'), 0.0013516754234886308)\n",
      "(('in', 'a'), 0.0013124332337744447)\n",
      "(('for', 'the'), 0.0013037127471712921)\n",
      "(('i', 'do'), 0.0012862717739649872)\n",
      "(('it', \"'s\"), 0.00126011031415553)\n",
      "((',', 'who'), 0.0012557500708539537)\n",
      "(('.', 'the'), 0.0012470295842508011)\n",
      "((',', 'so'), 0.00122522836774292)\n",
      "(('.', 'she'), 0.0012121476378381913)\n",
      "(('on', 'the'), 0.0011816259347271578)\n",
      "(('.', 'it'), 0.001164184961520853)\n",
      "(('at', 'the'), 0.0011598247182192766)\n",
      "(('as', 'if'), 0.0011380235017113955)\n",
      "(('it', '.'), 0.0010987813119972094)\n",
      "(('as', 'she'), 0.0010857005820924808)\n",
      "(('she', 'had'), 0.0010202969325688374)\n",
      "(('in', 'her'), 0.0009897752294578037)\n",
      "((',', 'jo'), 0.000937452309838889)\n",
      "(('her', ','), 0.0009330920665373128)\n",
      "(('she', 'was'), 0.0009243715799341604)\n",
      "((\"''\", 'and'), 0.0009200113366325841)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.0027425930366914474)\n",
      "(('in', 'the'), 0.0027295123067867188)\n",
      "(('do', \"n't\"), 0.0022498855436133337)\n",
      "(('with', 'a'), 0.0019272275392966927)\n",
      "(('and', 'i'), 0.0017179358608210339)\n",
      "(('and', 'the'), 0.001683053914408424)\n",
      "(('i', \"'m\"), 0.0016002092916784756)\n",
      "(('to', 'the'), 0.0015217249122501035)\n",
      "(('to', 'be'), 0.0014955634524406462)\n",
      "(('it', 'was'), 0.0013516754234886308)\n",
      "(('in', 'a'), 0.0013124332337744447)\n",
      "(('for', 'the'), 0.0013037127471712921)\n",
      "(('i', 'do'), 0.0012862717739649872)\n",
      "(('it', \"'s\"), 0.00126011031415553)\n",
      "(('on', 'the'), 0.0011816259347271578)\n",
      "(('at', 'the'), 0.0011598247182192766)\n",
      "(('as', 'if'), 0.0011380235017113955)\n",
      "(('as', 'she'), 0.0010857005820924808)\n",
      "(('she', 'had'), 0.0010202969325688374)\n",
      "(('in', 'her'), 0.0009897752294578037)\n",
      "(('she', 'was'), 0.0009243715799341604)\n",
      "(('but', 'i'), 0.0008982101201247029)\n",
      "(('of', 'her'), 0.0008982101201247029)\n",
      "(('with', 'the'), 0.000880769146918398)\n",
      "(('i', \"'ll\"), 0.0008764089036168218)\n",
      "(('was', 'a'), 0.0008720486603152456)\n",
      "(('a', 'little'), 0.0008371667139026358)\n",
      "(('and', 'a'), 0.0008066450107916021)\n",
      "(('of', 'a'), 0.0008066450107916021)\n",
      "(('for', 'a'), 0.0007761233076805686)\n",
      "(('did', \"n't\"), 0.0007630425777758399)\n",
      "(('ca', \"n't\"), 0.0007586823344742637)\n",
      "(('wo', \"n't\"), 0.0007238003880616538)\n",
      "(('if', 'you'), 0.0006801979550458916)\n",
      "(('to', 'her'), 0.0006758377117443154)\n",
      "(('to', 'do'), 0.0006671172251411628)\n",
      "(('the', 'little'), 0.0006583967385380104)\n",
      "(('mrs.', 'march'), 0.0006540364952364342)\n",
      "(('if', 'i'), 0.0006409557653317055)\n",
      "(('out', 'of'), 0.0006365955220301293)\n",
      "(('you', 'are'), 0.0006365955220301293)\n",
      "(('that', 'she'), 0.000632235278728553)\n",
      "(('to', 'see'), 0.000632235278728553)\n",
      "(('the', 'old'), 0.0006191545488238244)\n",
      "(('i', \"'ve\"), 0.0006147943055222481)\n",
      "(('it', 'is'), 0.0006060738189190957)\n",
      "(('did', 'not'), 0.0006017135756175195)\n",
      "(('with', 'her'), 0.0006017135756175195)\n",
      "(('like', 'a'), 0.000592993089014367)\n",
      "(('he', 'was'), 0.0005886328457127908)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('ca', \"n't\"), 0.0007586823344742637)\n",
      "(('wo', \"n't\"), 0.0007238003880616538)\n",
      "(('mrs.', 'march'), 0.0006540364952364342)\n",
      "(('said', 'jo'), 0.0005145087095859949)\n",
      "(('jo', \"'s\"), 0.00047526651987180886)\n",
      "(('would', \"n't\"), 0.000401142383745013)\n",
      "(('aunt', 'march'), 0.0003749809239355556)\n",
      "(('could', \"n't\"), 0.0003575399507292507)\n",
      "(('amy', \"'s\"), 0.0003270182476182171)\n",
      "(('said', 'meg'), 0.0003270182476182171)\n",
      "((\"n't\", 'know'), 0.0002964965445071835)\n",
      "(('project', 'gutenberg-tm'), 0.00024417362488826877)\n",
      "(('said', 'amy'), 0.00024417362488826877)\n",
      "(('beth', \"'s\"), 0.00022237240838038762)\n",
      "(('cried', 'jo'), 0.00022237240838038762)\n",
      "(('old', 'gentleman'), 0.00022237240838038762)\n",
      "(('meg', \"'s\"), 0.00020929167847565894)\n",
      "(('said', 'laurie'), 0.00020929167847565894)\n",
      "(('laurie', \"'s\"), 0.00020493143517408272)\n",
      "(('mother', \"'s\"), 0.0002005711918725065)\n",
      "(('old', 'lady'), 0.00018313021866620156)\n",
      "((\"n't\", 'think'), 0.0001744097320630491)\n",
      "((\"n't\", 'like'), 0.0001700494887614729)\n",
      "((\"'m\", 'afraid'), 0.00016568924545989666)\n",
      "((\"'ve\", 'got'), 0.00016568924545989666)\n",
      "(('one', 'another'), 0.0001569687588567442)\n",
      "((\"'m\", 'glad'), 0.00014824827225359176)\n",
      "((\"'s\", 'face'), 0.00014824827225359176)\n",
      "(('asked', 'jo'), 0.00014824827225359176)\n",
      "(('young', 'lady'), 0.00014824827225359176)\n",
      "((\"n't\", 'help'), 0.0001438880289520155)\n",
      "((\"n't\", 'care'), 0.00013952778565043929)\n",
      "(('every', 'day'), 0.00013516754234886306)\n",
      "((\"'m\", 'going'), 0.00013080729904728683)\n",
      "((\"n't\", 'see'), 0.00013080729904728683)\n",
      "(('project', 'gutenberg'), 0.00013080729904728683)\n",
      "(('said', 'beth'), 0.00013080729904728683)\n",
      "(('father', \"'s\"), 0.0001264470557457106)\n",
      "((\"'m\", 'sure'), 0.00012208681244413438)\n",
      "(('said', 'mrs.'), 0.00012208681244413438)\n",
      "(('young', 'ladies'), 0.00012208681244413438)\n",
      "((\"n't\", 'let'), 0.00011336632584098192)\n",
      "(('good', 'deal'), 0.0001090060825394057)\n",
      "(('great', 'deal'), 0.0001090060825394057)\n",
      "((\"n't\", 'get'), 0.0001090060825394057)\n",
      "((\"n't\", 'go'), 0.0001090060825394057)\n",
      "((\"n't\", 'mind'), 0.0001090060825394057)\n",
      "((\"'ll\", 'go'), 0.00010464583923782947)\n",
      "(('dare', 'say'), 0.00010464583923782947)\n",
      "(('asked', 'laurie'), 0.00010028559593625325)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(lambda w: w in stopwords1)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('#', '514'), 17.80715992969259)\n",
      "(('&', 'co.'), 17.80715992969259)\n",
      "((\"'_ein\", 'wonderschones'), 17.80715992969259)\n",
      "((\"'_femme\", 'peinte'), 17.80715992969259)\n",
      "((\"'_parley\", 'vooing_'), 17.80715992969259)\n",
      "((\"'_sonata\", 'pathetique_'), 17.80715992969259)\n",
      "((\"'die\", 'erste'), 17.80715992969259)\n",
      "((\"'enfant\", 'terrible'), 17.80715992969259)\n",
      "((\"'gentleman\", 'growed'), 17.80715992969259)\n",
      "((\"'ittle\", \"'tar\"), 17.80715992969259)\n",
      "((\"'maria\", 'theresa'), 17.80715992969259)\n",
      "((\"'nil\", 'desperandum'), 17.80715992969259)\n",
      "((\"'samphire'\", 'correction'), 17.80715992969259)\n",
      "(('4557', 'melan'), 17.80715992969259)\n",
      "(('_a', 'la_'), 17.80715992969259)\n",
      "(('_blarneystone', 'banner_'), 17.80715992969259)\n",
      "(('_little', 'women_'), 17.80715992969259)\n",
      "(('_tres', 'magnifique_'), 17.80715992969259)\n",
      "(('_uncle', 'tom_'), 17.80715992969259)\n",
      "(('_very', 'private_'), 17.80715992969259)\n",
      "(('ad', 'libitum'), 17.80715992969259)\n",
      "(('ants', 'partook'), 17.80715992969259)\n",
      "(('arabian', 'steeds'), 17.80715992969259)\n",
      "(('artificial', 'jaws'), 17.80715992969259)\n",
      "(('assistant', 'cooks'), 17.80715992969259)\n",
      "(('au', 'revoir'), 17.80715992969259)\n",
      "(('bass', 'viol'), 17.80715992969259)\n",
      "(('beatified', 'countenances'), 17.80715992969259)\n",
      "(('bequeaths', 'untold'), 17.80715992969259)\n",
      "(('biscuits', 'speckled'), 17.80715992969259)\n",
      "(('blond', 'mustaches'), 17.80715992969259)\n",
      "(('calmer', 'waters'), 17.80715992969259)\n",
      "(('caroline', 'percy'), 17.80715992969259)\n",
      "(('castoff', 'palettes'), 17.80715992969259)\n",
      "(('catastrophe', 'clears'), 17.80715992969259)\n",
      "(('cette', 'jeune'), 17.80715992969259)\n",
      "(('champs', 'elysees'), 17.80715992969259)\n",
      "(('characteristically', 'observes'), 17.80715992969259)\n",
      "(('childlike', 'candor'), 17.80715992969259)\n",
      "(('chivalrous', 'reluctance'), 17.80715992969259)\n",
      "(('chuckling', 'ecstatically'), 17.80715992969259)\n",
      "(('citron', 'blooms'), 17.80715992969259)\n",
      "(('classic', 'draperies'), 17.80715992969259)\n",
      "(('claws', 'pathetically'), 17.80715992969259)\n",
      "(('common-place', 'dauber'), 17.80715992969259)\n",
      "(('complacent', 'wraith'), 17.80715992969259)\n",
      "(('conflicting', 'conjectures'), 17.80715992969259)\n",
      "(('conjugal', 'strolls'), 17.80715992969259)\n",
      "(('copiously', 'anointed'), 17.80715992969259)\n",
      "(('coralline', 'salve'), 17.80715992969259)\n"
     ]
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(advhfwords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('#', '514'), 17.80715992969259)\n",
      "(('&', 'co.'), 17.80715992969259)\n",
      "((\"'_ein\", 'wonderschones'), 17.80715992969259)\n",
      "((\"'_femme\", 'peinte'), 17.80715992969259)\n",
      "((\"'_parley\", 'vooing_'), 17.80715992969259)\n",
      "((\"'_sonata\", 'pathetique_'), 17.80715992969259)\n",
      "((\"'die\", 'erste'), 17.80715992969259)\n",
      "((\"'enfant\", 'terrible'), 17.80715992969259)\n",
      "((\"'gentleman\", 'growed'), 17.80715992969259)\n",
      "((\"'ittle\", \"'tar\"), 17.80715992969259)\n",
      "((\"'maria\", 'theresa'), 17.80715992969259)\n",
      "((\"'nil\", 'desperandum'), 17.80715992969259)\n",
      "((\"'samphire'\", 'correction'), 17.80715992969259)\n",
      "(('4557', 'melan'), 17.80715992969259)\n",
      "(('_a', 'la_'), 17.80715992969259)\n",
      "(('_blarneystone', 'banner_'), 17.80715992969259)\n",
      "(('_little', 'women_'), 17.80715992969259)\n",
      "(('_tres', 'magnifique_'), 17.80715992969259)\n",
      "(('_uncle', 'tom_'), 17.80715992969259)\n",
      "(('_very', 'private_'), 17.80715992969259)\n",
      "(('ad', 'libitum'), 17.80715992969259)\n",
      "(('ants', 'partook'), 17.80715992969259)\n",
      "(('arabian', 'steeds'), 17.80715992969259)\n",
      "(('artificial', 'jaws'), 17.80715992969259)\n",
      "(('assistant', 'cooks'), 17.80715992969259)\n",
      "(('au', 'revoir'), 17.80715992969259)\n",
      "(('bass', 'viol'), 17.80715992969259)\n",
      "(('beatified', 'countenances'), 17.80715992969259)\n",
      "(('bequeaths', 'untold'), 17.80715992969259)\n",
      "(('biscuits', 'speckled'), 17.80715992969259)\n"
     ]
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(advhfwords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('blanc', 'mange'), 15.222197428971434)\n",
      "(('don', 'pedro'), 14.999805007634986)\n",
      "(('dr.', 'bangs'), 14.414842506913828)\n",
      "(('united', 'states'), 13.862301483885052)\n",
      "(('public', 'domain'), 13.807159929692592)\n",
      "(('rag', 'bag'), 13.514378180464744)\n",
      "(('literary', 'archive'), 13.283597973635576)\n",
      "(('archive', 'foundation'), 13.052272427529122)\n",
      "(('falling', 'summer'), 12.862301483885052)\n",
      "(('clock', 'struck'), 12.711235509694054)\n",
      "(('post', 'office'), 12.677876912747625)\n",
      "(('http', ':'), 12.597706564063643)\n",
      "(('ice', 'cream'), 12.456662682608458)\n",
      "(('beg', 'pardon'), 12.173834407410036)\n",
      "(('gutenberg', 'literary'), 12.07714709616815)\n",
      "(('cocked', 'hat'), 11.999805007634988)\n",
      "(('fifteen', 'minutes'), 11.900269334084072)\n",
      "(('summer', 'rain'), 11.669656405942657)\n",
      "(('electronic', 'works'), 11.626007672827026)\n",
      "(('gutenberg-tm', 'electronic'), 11.414842506913832)\n",
      "(('project', 'gutenberg'), 11.331426498726191)\n",
      "(('project', 'gutenberg-tm'), 11.331426498726191)\n",
      "(('annie', 'moffat'), 11.315306833362918)\n",
      "(('miss', 'crocker'), 11.025800216167932)\n",
      "(('miss', 'norton'), 11.02580021616793)\n",
      "(('gutenberg-tm', 'license'), 10.999805007634988)\n",
      "(('merry', 'christmas'), 10.936795210109187)\n",
      "(('dining', 'room'), 10.912342166384647)\n",
      "(('years', 'ago'), 10.531035524418353)\n",
      "(('set', 'forth'), 10.520917224327754)\n"
     ]
    }
   ],
   "source": [
    "# first apply frequency filter of 5\n",
    "finder3.apply_freq_filter(5)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('blanc', 'mange'), 15.222197428971434)\n",
      "(('don', 'pedro'), 14.999805007634986)\n",
      "(('dr.', 'bangs'), 14.414842506913828)\n",
      "(('united', 'states'), 13.862301483885052)\n",
      "(('public', 'domain'), 13.807159929692592)\n",
      "(('rag', 'bag'), 13.514378180464744)\n",
      "(('literary', 'archive'), 13.283597973635576)\n",
      "(('archive', 'foundation'), 13.052272427529122)\n",
      "(('falling', 'summer'), 12.862301483885052)\n",
      "(('clock', 'struck'), 12.711235509694054)\n",
      "(('post', 'office'), 12.677876912747625)\n",
      "(('http', ':'), 12.597706564063643)\n",
      "(('ice', 'cream'), 12.456662682608458)\n",
      "(('beg', 'pardon'), 12.173834407410036)\n",
      "(('gutenberg', 'literary'), 12.07714709616815)\n",
      "(('cocked', 'hat'), 11.999805007634988)\n",
      "(('fifteen', 'minutes'), 11.900269334084072)\n",
      "(('summer', 'rain'), 11.669656405942657)\n",
      "(('electronic', 'works'), 11.626007672827026)\n",
      "(('gutenberg-tm', 'electronic'), 11.414842506913832)\n",
      "(('project', 'gutenberg'), 11.331426498726191)\n",
      "(('project', 'gutenberg-tm'), 11.331426498726191)\n",
      "(('annie', 'moffat'), 11.315306833362918)\n",
      "(('miss', 'crocker'), 11.025800216167932)\n",
      "(('miss', 'norton'), 11.02580021616793)\n",
      "(('gutenberg-tm', 'license'), 10.999805007634988)\n",
      "(('merry', 'christmas'), 10.936795210109187)\n",
      "(('dining', 'room'), 10.912342166384647)\n",
      "(('years', 'ago'), 10.531035524418353)\n",
      "(('set', 'forth'), 10.520917224327754)\n",
      "(('ned', 'moffat'), 10.476243051577974)\n",
      "(('flew', 'open'), 10.186573519240714)\n",
      "(('few', 'minutes'), 10.055920204544266)\n",
      "(('miss', 'kate'), 10.02580021616793)\n",
      "(('several', 'minutes'), 10.007184538000585)\n",
      "(('mrs.', 'k.'), 9.918416680794332)\n",
      "(('mrs.', 'kirke'), 9.818881007243418)\n",
      "(('aunt', 'carrol'), 9.762765810334137)\n",
      "(('god', 'bless'), 9.756222964467366)\n",
      "(('read', 'aloud'), 9.75079316866806)\n",
      "(('mrs.', 'hummel'), 9.655382274960537)\n",
      "(('drawing', 'room'), 9.590414071497285)\n",
      "(('easy', 'chair'), 9.584537505160618)\n",
      "(('dozen', 'times'), 9.570667311311288)\n",
      "(('without', 'stopping'), 9.521757710830341)\n",
      "(('anyone', 'else'), 9.497304667105803)\n",
      "(('mr.', 'dashwood'), 9.481292349117172)\n",
      "(('bad', 'effect'), 9.455778949018258)\n",
      "(('new', 'member'), 9.443463184853599)\n",
      "(('miss', 'belle'), 9.288834622001724)\n"
     ]
    }
   ],
   "source": [
    "# first apply frequency filter of 5\n",
    "finder3.apply_freq_filter(5)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder4 = TrigramCollocationFinder.from_words(advhfTokens)\n",
    "scored4 = finder4.score_ngrams(trigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder4 = TrigramCollocationFinder.from_words(advhfTokens)\n",
    "scored4 = finder4.score_ngrams(trigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(trigram for trigram, score in scored4) == set(nltk.trigrams(advhfTokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', \"''\", 'said'), ('.', \"''\", '``')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(finder4.nbest(trigram_measures.raw_freq, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder.apply_word_filter(alpha_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder4.apply_word_filter(alpha_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('in', 'spite', 'of'), 0.0003139375177134884)\n",
      "(('as', 'well', 'as'), 0.00020929167847565894)\n",
      "(('one', 'of', 'the'), 0.00019621094857093027)\n",
      "(('out', 'of', 'the'), 0.0001744097320630491)\n",
      "(('as', 'if', 'she'), 0.00016132900215832044)\n",
      "(('do', \"n't\", 'know'), 0.00016132900215832044)\n",
      "(('as', 'if', 'he'), 0.00013952778565043929)\n",
      "(('It', \"'s\", 'a'), 0.00013080729904728683)\n",
      "(('the', 'old', 'lady'), 0.00013080729904728683)\n",
      "(('she', 'did', 'not'), 0.0001264470557457106)\n",
      "(('the', 'old', 'gentleman'), 0.0001264470557457106)\n",
      "(('a', 'pair', 'of'), 0.00012208681244413438)\n",
      "(('and', 'do', \"n't\"), 0.00012208681244413438)\n",
      "(('in', 'the', 'world'), 0.00012208681244413438)\n",
      "(('that', 'she', 'had'), 0.00012208681244413438)\n",
      "(('do', \"n't\", 'think'), 0.00011336632584098192)\n",
      "(('now', 'and', 'then'), 0.00011336632584098192)\n",
      "(('there', 'was', 'a'), 0.00011336632584098192)\n",
      "((\"'m\", 'going', 'to'), 0.0001090060825394057)\n",
      "(('a', 'great', 'deal'), 0.0001090060825394057)\n",
      "(('if', 'she', 'had'), 0.0001090060825394057)\n",
      "(('said', 'Mrs.', 'March'), 0.0001090060825394057)\n",
      "(('to', 'be', 'a'), 0.0001090060825394057)\n",
      "(('Do', \"n't\", 'you'), 0.00010464583923782947)\n",
      "(('all', 'sorts', 'of'), 0.00010464583923782947)\n",
      "(('that', 'it', 'was'), 0.00010464583923782947)\n",
      "(('that', 'she', 'was'), 0.00010464583923782947)\n",
      "(('a', 'good', 'deal'), 0.00010028559593625325)\n",
      "(('as', 'much', 'as'), 0.00010028559593625325)\n",
      "(('to', 'do', 'it'), 0.00010028559593625325)\n",
      "(('for', 'a', 'minute'), 9.592535263467702e-05)\n",
      "(('it', 'was', 'a'), 9.592535263467702e-05)\n",
      "(('there', 'was', 'no'), 9.592535263467702e-05)\n",
      "(('do', \"n't\", 'believe'), 8.720486603152456e-05)\n",
      "(('do', \"n't\", 'care'), 8.720486603152456e-05)\n",
      "(('her', 'mother', \"'s\"), 8.720486603152456e-05)\n",
      "(('wo', \"n't\", 'be'), 8.720486603152456e-05)\n",
      "(('an', 'air', 'of'), 8.284462272994833e-05)\n",
      "(('as', 'if', 'the'), 8.284462272994833e-05)\n",
      "(('did', \"n't\", 'know'), 8.284462272994833e-05)\n",
      "(('do', \"n't\", 'see'), 8.284462272994833e-05)\n",
      "(('for', 'she', 'had'), 8.284462272994833e-05)\n",
      "(('it', 'would', 'be'), 8.284462272994833e-05)\n",
      "(('she', 'had', 'been'), 8.284462272994833e-05)\n",
      "(('you', 'do', \"n't\"), 8.284462272994833e-05)\n",
      "(('Project', 'Gutenberg-tm', 'electronic'), 7.84843794283721e-05)\n",
      "(('You', 'do', \"n't\"), 7.84843794283721e-05)\n",
      "(('and', 'no', 'one'), 7.84843794283721e-05)\n",
      "((\"n't\", 'mean', 'to'), 7.84843794283721e-05)\n",
      "(('spite', 'of', 'the'), 7.84843794283721e-05)\n"
     ]
    }
   ],
   "source": [
    "scored5 = finder4.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored5[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('blanc', 'mange'), 15.222197428971434)\n",
      "(('don', 'pedro'), 14.999805007634986)\n",
      "(('dr.', 'bangs'), 14.414842506913828)\n",
      "(('united', 'states'), 13.862301483885052)\n",
      "(('public', 'domain'), 13.807159929692592)\n",
      "(('rag', 'bag'), 13.514378180464744)\n",
      "(('literary', 'archive'), 13.283597973635576)\n",
      "(('archive', 'foundation'), 13.052272427529122)\n",
      "(('falling', 'summer'), 12.862301483885052)\n",
      "(('clock', 'struck'), 12.711235509694054)\n",
      "(('post', 'office'), 12.677876912747625)\n",
      "(('http', ':'), 12.597706564063643)\n",
      "(('ice', 'cream'), 12.456662682608458)\n",
      "(('beg', 'pardon'), 12.173834407410036)\n",
      "(('gutenberg', 'literary'), 12.07714709616815)\n",
      "(('cocked', 'hat'), 11.999805007634988)\n",
      "(('fifteen', 'minutes'), 11.900269334084072)\n",
      "(('summer', 'rain'), 11.669656405942657)\n",
      "(('electronic', 'works'), 11.626007672827026)\n",
      "(('gutenberg-tm', 'electronic'), 11.414842506913832)\n",
      "(('project', 'gutenberg'), 11.331426498726191)\n",
      "(('project', 'gutenberg-tm'), 11.331426498726191)\n",
      "(('annie', 'moffat'), 11.315306833362918)\n",
      "(('miss', 'crocker'), 11.025800216167932)\n",
      "(('miss', 'norton'), 11.02580021616793)\n",
      "(('gutenberg-tm', 'license'), 10.999805007634988)\n",
      "(('merry', 'christmas'), 10.936795210109187)\n",
      "(('dining', 'room'), 10.912342166384647)\n",
      "(('years', 'ago'), 10.531035524418353)\n",
      "(('set', 'forth'), 10.520917224327754)\n",
      "(('ned', 'moffat'), 10.476243051577974)\n",
      "(('flew', 'open'), 10.186573519240714)\n",
      "(('few', 'minutes'), 10.055920204544266)\n",
      "(('miss', 'kate'), 10.02580021616793)\n",
      "(('several', 'minutes'), 10.007184538000585)\n",
      "(('mrs.', 'k.'), 9.918416680794332)\n",
      "(('mrs.', 'kirke'), 9.818881007243418)\n",
      "(('aunt', 'carrol'), 9.762765810334137)\n",
      "(('god', 'bless'), 9.756222964467366)\n",
      "(('read', 'aloud'), 9.75079316866806)\n",
      "(('mrs.', 'hummel'), 9.655382274960537)\n",
      "(('drawing', 'room'), 9.590414071497285)\n",
      "(('easy', 'chair'), 9.584537505160618)\n",
      "(('dozen', 'times'), 9.570667311311288)\n",
      "(('without', 'stopping'), 9.521757710830341)\n",
      "(('anyone', 'else'), 9.497304667105803)\n",
      "(('mr.', 'dashwood'), 9.481292349117172)\n",
      "(('bad', 'effect'), 9.455778949018258)\n",
      "(('new', 'member'), 9.443463184853599)\n",
      "(('miss', 'belle'), 9.288834622001724)\n"
     ]
    }
   ],
   "source": [
    "finder4.apply_word_filter(lambda w: w in stopwords1)\n",
    "scored6 = finder4.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('said', 'Mrs.', 'March'), 0.0001090060825394057)\n",
      "(('Project', 'Gutenberg-tm', 'electronic'), 7.84843794283721e-05)\n",
      "(('ca', \"n't\", 'help'), 6.976389282521964e-05)\n",
      "(('could', \"n't\", 'help'), 6.976389282521964e-05)\n",
      "(('Gutenberg', 'Literary', 'Archive'), 5.668316292049096e-05)\n",
      "(('Literary', 'Archive', 'Foundation'), 5.668316292049096e-05)\n",
      "(('Project', 'Gutenberg', 'Literary'), 5.668316292049096e-05)\n",
      "(('Gutenberg-tm', 'electronic', 'works'), 5.2322919618914735e-05)\n",
      "(('ca', \"n't\", 'get'), 5.2322919618914735e-05)\n",
      "(('You', 'ca', \"n't\"), 4.796267631733851e-05)\n",
      "(('It', 'wo', \"n't\"), 4.360243301576228e-05)\n",
      "(('Mr.', 'Laurence', \"'s\"), 4.360243301576228e-05)\n",
      "(('Aunt', 'March', \"'s\"), 3.924218971418605e-05)\n",
      "(('Mrs.', 'March', \"'s\"), 3.924218971418605e-05)\n",
      "(('Project', 'Gutenberg-tm', 'License'), 3.488194641260982e-05)\n",
      "(('wo', \"n't\", 'let'), 3.488194641260982e-05)\n",
      "(('It', \"'s\", 'like'), 3.0521703111033596e-05)\n",
      "(('Jo', \"'s\", 'face'), 3.0521703111033596e-05)\n",
      "(('Jo', \"'s\", 'heart'), 3.0521703111033596e-05)\n",
      "(('Mr.', 'Brooke', \"'s\"), 3.0521703111033596e-05)\n",
      "(('We', 'ca', \"n't\"), 3.0521703111033596e-05)\n",
      "(('heart', \"'s\", 'content'), 3.0521703111033596e-05)\n",
      "((\"n't\", 'know', 'anything'), 3.0521703111033596e-05)\n",
      "((\"n't\", 'say', 'anything'), 3.0521703111033596e-05)\n",
      "(('said', 'Mr.', 'Brooke'), 3.0521703111033596e-05)\n",
      "(('Gutenberg-tm', 'electronic', 'work'), 2.6161459809457368e-05)\n",
      "(('Mrs.', 'March', 'said'), 2.6161459809457368e-05)\n",
      "(('New', 'Year', \"'s\"), 2.6161459809457368e-05)\n",
      "(('The', 'old', 'gentleman'), 2.6161459809457368e-05)\n",
      "(('You', 'need', \"n't\"), 2.6161459809457368e-05)\n",
      "(('You', 'wo', \"n't\"), 2.6161459809457368e-05)\n",
      "(('asked', 'Mrs.', 'March'), 2.6161459809457368e-05)\n",
      "(('said', 'Jo', 'decidedly'), 2.6161459809457368e-05)\n",
      "(('wo', \"n't\", 'go'), 2.6161459809457368e-05)\n",
      "(('young', 'man', \"'s\"), 2.6161459809457368e-05)\n",
      "(('Do', \"n't\", 'cry'), 2.180121650788114e-05)\n",
      "(('Do', \"n't\", 'laugh'), 2.180121650788114e-05)\n",
      "(('Do', \"n't\", 'let'), 2.180121650788114e-05)\n",
      "(('Do', \"n't\", 'say'), 2.180121650788114e-05)\n",
      "(('Mr.', 'Bhaer', \"'s\"), 2.180121650788114e-05)\n",
      "(('Mr.', 'Brooke', 'looked'), 2.180121650788114e-05)\n",
      "(('Mrs.', 'March', 'looked'), 2.180121650788114e-05)\n",
      "(('Project', 'Gutenberg-tm', 'work'), 2.180121650788114e-05)\n",
      "(('Project', 'Gutenberg-tm', 'works'), 2.180121650788114e-05)\n",
      "(('The', 'little', 'girls'), 2.180121650788114e-05)\n",
      "(('bad', 'effect', 'upon'), 2.180121650788114e-05)\n",
      "(('ca', \"n't\", 'say'), 2.180121650788114e-05)\n",
      "(('falling', 'summer', 'rain'), 2.180121650788114e-05)\n",
      "(('full', 'Project', 'Gutenberg-tm'), 2.180121650788114e-05)\n",
      "(('love', 'one', 'another'), 2.180121650788114e-05)\n"
     ]
    }
   ],
   "source": [
    "scored5 = finder4.score_ngrams(trigram_measures.raw_freq)\n",
    "for bscore in scored5[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('said', 'Mrs.', 'March'), 0.0001090060825394057)\n",
      "(('Project', 'Gutenberg-tm', 'electronic'), 7.84843794283721e-05)\n",
      "(('ca', \"n't\", 'help'), 6.976389282521964e-05)\n",
      "(('could', \"n't\", 'help'), 6.976389282521964e-05)\n",
      "(('Gutenberg', 'Literary', 'Archive'), 5.668316292049096e-05)\n",
      "(('Literary', 'Archive', 'Foundation'), 5.668316292049096e-05)\n",
      "(('Project', 'Gutenberg', 'Literary'), 5.668316292049096e-05)\n",
      "(('Gutenberg-tm', 'electronic', 'works'), 5.2322919618914735e-05)\n",
      "(('ca', \"n't\", 'get'), 5.2322919618914735e-05)\n",
      "(('You', 'ca', \"n't\"), 4.796267631733851e-05)\n",
      "(('It', 'wo', \"n't\"), 4.360243301576228e-05)\n",
      "(('Mr.', 'Laurence', \"'s\"), 4.360243301576228e-05)\n",
      "(('Aunt', 'March', \"'s\"), 3.924218971418605e-05)\n",
      "(('Mrs.', 'March', \"'s\"), 3.924218971418605e-05)\n",
      "(('Project', 'Gutenberg-tm', 'License'), 3.488194641260982e-05)\n",
      "(('wo', \"n't\", 'let'), 3.488194641260982e-05)\n",
      "(('It', \"'s\", 'like'), 3.0521703111033596e-05)\n",
      "(('Jo', \"'s\", 'face'), 3.0521703111033596e-05)\n",
      "(('Jo', \"'s\", 'heart'), 3.0521703111033596e-05)\n",
      "(('Mr.', 'Brooke', \"'s\"), 3.0521703111033596e-05)\n",
      "(('We', 'ca', \"n't\"), 3.0521703111033596e-05)\n",
      "(('heart', \"'s\", 'content'), 3.0521703111033596e-05)\n",
      "((\"n't\", 'know', 'anything'), 3.0521703111033596e-05)\n",
      "((\"n't\", 'say', 'anything'), 3.0521703111033596e-05)\n",
      "(('said', 'Mr.', 'Brooke'), 3.0521703111033596e-05)\n",
      "(('Gutenberg-tm', 'electronic', 'work'), 2.6161459809457368e-05)\n",
      "(('Mrs.', 'March', 'said'), 2.6161459809457368e-05)\n",
      "(('New', 'Year', \"'s\"), 2.6161459809457368e-05)\n",
      "(('The', 'old', 'gentleman'), 2.6161459809457368e-05)\n",
      "(('You', 'need', \"n't\"), 2.6161459809457368e-05)\n",
      "(('You', 'wo', \"n't\"), 2.6161459809457368e-05)\n",
      "(('asked', 'Mrs.', 'March'), 2.6161459809457368e-05)\n",
      "(('said', 'Jo', 'decidedly'), 2.6161459809457368e-05)\n",
      "(('wo', \"n't\", 'go'), 2.6161459809457368e-05)\n",
      "(('young', 'man', \"'s\"), 2.6161459809457368e-05)\n",
      "(('Do', \"n't\", 'cry'), 2.180121650788114e-05)\n",
      "(('Do', \"n't\", 'laugh'), 2.180121650788114e-05)\n",
      "(('Do', \"n't\", 'let'), 2.180121650788114e-05)\n",
      "(('Do', \"n't\", 'say'), 2.180121650788114e-05)\n",
      "(('Mr.', 'Bhaer', \"'s\"), 2.180121650788114e-05)\n",
      "(('Mr.', 'Brooke', 'looked'), 2.180121650788114e-05)\n",
      "(('Mrs.', 'March', 'looked'), 2.180121650788114e-05)\n",
      "(('Project', 'Gutenberg-tm', 'work'), 2.180121650788114e-05)\n",
      "(('Project', 'Gutenberg-tm', 'works'), 2.180121650788114e-05)\n",
      "(('The', 'little', 'girls'), 2.180121650788114e-05)\n",
      "(('bad', 'effect', 'upon'), 2.180121650788114e-05)\n",
      "(('ca', \"n't\", 'say'), 2.180121650788114e-05)\n",
      "(('falling', 'summer', 'rain'), 2.180121650788114e-05)\n",
      "(('full', 'Project', 'Gutenberg-tm'), 2.180121650788114e-05)\n",
      "(('love', 'one', 'another'), 2.180121650788114e-05)\n"
     ]
    }
   ],
   "source": [
    "finder4.apply_word_filter(lambda w: w in stopwords1)\n",
    "scored6 = finder4.score_ngrams(trigram_measures.raw_freq)\n",
    "for bscore in scored6[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
